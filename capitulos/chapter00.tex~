\chapter{Introduction}
\label{chap:introduction}

\section{Background}
Soil science is experiencing a period of renaissance that started in the last decade \cite{HarteminkEtAl2008}. It is a result of a new global demand for soil information needed to solve what has been defined as the five major problems of our time: food security, climate change, environmental degradation, water scarcity and threats to the biodiversity \cite{SanchezEtAl2009}. The Food and Agriculture Organization (\href{http://www.fao.org/index_en.htm}{FAO}) of the United Nations (\href{http://www.un.org/en/}{UN}), through the Global Soil Partnership (\href{http://www.fao.org/globalsoilpartnership/en/}{GSP}) project, is the main global demander of up-to-date soil information. The objective of FAO is to support and ensure the implementation of joint efforts that lead to the adoption of sustainable development goals for the soils \cite{FAO2012}. Digital soil mapping (DSM), \textit{the} \textit{creation and population of spatial soil information systems through the use of field and laboratory observational methods, coupled with spatial and non-spatial soil inference systems} \cite{LagacherieEtAl2007a}, a branch of pedometrics, a new emerging discipline of soil science that corresponds to the \textit{application of mathematical and statistical methods for the study of the distribution and genesis of soils} \cite{Heuvelink2003}, is the best alternative to meet this new demand for soil information. This is because DSM addresses the main problems of the classical approach of soil mapping \cite{Kempen2011}. First, DSM is data-centered (\textit{environmental-centered}) and gives emphasis on producing soil information according to the needs of soil information users (\textit{user-driven}). Second, DSM relies on using well documented statistical models (\textit{reproducible research}) that allow treating the soil as a continuum (models of spatial variation). And third, DSM products can be made available at a lower cost in soil information systems with quantified uncertainty.

Several initiatives have been undertaken around the world in the last years to ensure the development and implementation of DSM. The main examples are the GlobalSoilMap.net consortium and ISRIC's Global Soil Information Facilities (\href{http://www.isric.org/projects/global-soil-information-facilities-gsif}{GSIF}). In Brazil, soil scientists created the Brazilian Network for Research in DSM (RedeMDS) with the main objective of generating synergy among Brazilian soil scientists to advance the research in DSM in Brazil \cite{RedeMDS2013}. Also, the two first job positions for assistant professors in Pedometrics and DSM in Brazilian universities were created in 2011 and 2013 \cite{UFRRJ2011,UFSM2012}. Unfortunately these local initiatives are not supported by any official government demand for up-to-date soil information in Brazil \cite{SamuelRosa2012}. Several economic, politic and cultural reasons have been pointed out to explain the lack of interest on soil information in Brazil since the 1980s \cite{Dalmolin1999,Ker1999,KerEtAl2003,Ramos2003,Espindola2008}, but their resolution is out of the scope of this PhD project proposal. Alike many other local initiatives, the present PhD project proposal complies with the priorities defined by the 75 soil scientists from 17 countries that came together in Rio de Janeiro on July 2006 during the 2nd Global Workshop on Digital Soil Mapping, for whom developing and implementing DSM depends on training students and experienced soil scientists, standardizing methods and measures, and building international collaboration \cite{Boettinger2004}.

\section{Digital soil mapping}

\subsection{Digital soil mapping framework}
In general terms, the DSM framework can be described as a series of seven steps as follows:

\begin{description}
\item [{Step~0}] Identify a reality or problem entity: geographic region where pedometric techniques will be used to model the soil property(ies) distribution in the geographic and attribute spaces in a given time period;

\item [{Step~1}] Develop a conceptual model of pedogenesis: verbal representation of the reality or problem entity including the explicit description of soil forming factors and processes that drive soil characteristics and its spatial distribution pattern. This step relies on gathering all environmental information available and applying concepts (expert knowledge) of soil-landscape system, catenary soil development or other theoretical model of explanation of soil spatial variation;

\item [{Step~2}] Develop a mathematical representation: translate the verbal representation of the reality or problem entity into a set of possible mathematical representations. In this step we use the conceptual model of pedogenesis to define the sample design and the number of soil observations needed to calibrate the DSM model, collect predictor variables from available environmental ancillary data (environmental co-variates), specify model structure (linear or nonlinear) and define the techniques to be used in the remainder of the DSM modeling activity (tests of independence, normality and homoscedasticity, multicollinearity assessment, variable selection method, goodness-of-fit measures, etc). Several of this tasks can be (and usually are) carried out with the aid of a data processing environment such as a computer;

\item [{Step~3}] Develop a computer representation: translate the set of mathematical representations of the reality or problem entity into a computer representation, that is, a computer code or computer script. The computer code is used to establish the communication between the DSM modeler (a human being) and the data processing environment (a computer) where mathematical representations and DSM model assessment tools are implemented. Developing a computer code that describes all processing steps is at the core of the concept of \textit{reproducible research} in DSM;

\item [{Step~4}] Data analysis: run the computer code and evaluate the outcomes. This includes the univariate analysis and selection of candidate predictor variables, followed by its multivariate analysis, and evaluation of the adequacy of multivariate model(s), namely check model assumptions, look for interactions between predictor variables, evaluate goodness-of-fit measures and visually assess preliminary soil maps. Best performing DSM model(s) are evaluated regarding their tenability (pedological evaluation) and how well they represent the range of possible mathematical models. Failure in this last assessment means that DSM model(s) have to be adjusted and data analysis rerun, or can simply be discarded;

\item [{Step~5}] Make predictions: application of best performing DSM model(s) to predict soil property values and confidence interval at unvisited locations;

\item [{Step~6}] Statistical validation: validate the set of DSM models using existing independent field data and select the best performing model using a statistical criterion. Best performing DSM model is assumed to be the best mathematical representation of the reality or problem entity under consideration. If previous steps have already allowed selecting a single best performing DSM model, statistical validation is used only to assess model accuracy;

\item [{Step~7}] Reformulate the conceptual model of pedogenesis: selected DSM model and prediction and uncertainty maps can provide new insights about the reality or problem entity, and thus allow reformulating or improving the verbal representation of the conceptual model of pedogenesis;

\item [{Step~8}] Populate spatial soil information systems: point soil observations, prediction and uncertainty maps, and metadata are used to populate a spatial soil information system and made available for inspection through different visualization techniques.
\end{description}

\subsection{Sources of uncertainty}

Despite the ease of building DSM models, their performance is quite variable and usually lies between 20\% and 70\% of soil property variance explanation \cite{MooreEtAl1993,OdehEtAl1994,GesslerEtAl1995,McKenzieEtAl1999,GobinEtAl2001,SumflethEtAl2008,SunEtAl2012}. More complex nonlinear models can be used to predict soil properties with greater accuracy, but they can be devoid of pedological information \cite{Grunwald2009}. Environmental co-variates used to fit DSM models contain varying levels of error \cite{HeuvelinkEtAl1989}. The diversity of statistical methods available for soil data analysis can lead to significantly different results \cite{ParkEtAl2002}. Soil observations can be biased and poorly cover the geographic and feature spaces \cite{HenglEtAl2003a,BrusEtAl2007a}. Laboratory errors and positional accuracy of global positioning equipment can also affect prediction accuracy. Besides, some soil properties naturally contain more errors due to analytical procedures. In the case of particle-size distribution, the error is propagated to the fraction obtained by difference. Pre-treatments, such as organic matter oxidation, can change mineral structure \cite{MikuttaEtAl2005a}. The way compositional data is handled also affects predicted values \cite{LarkEtAl2007}. Finally, the conceptual model of pedogenesis can be poorly formulated, and a poor DSM model can mislead its reformulation. Among all these sources of uncertainty, three of them are believed to have a major impact on model building and spatial prediction. They can be classified into three categories for didactic purposes: a) calibration observations, b) environmental co-variates, and c) model structure.

\subsubsection{Calibration observations}

Real-world soil data usually come from soil surveys where the number and location of calibration observations are defined based on the tacit knowledge of soil surveyors \cite{BrusEtAl2007a}. Several criteria are used by soil surveyors and, whenever possible, they attempt to obtain a nice distribution of observations in the geographic space. But this attempt is often held back by the availability of financial resources, staff, time, presence of geographic accidents and prohibition of access in private properties \cite{KempenEtAl2012,SamuelRosa2012}. Because of these issues, soil surveyors rarely use (geo)statistical criteria and usually obtain larger sampling densities in more complex and less known areas \cite{Rossiter2000}. This can cause both the selection of an insufficient as to an exaggerated number of samples \cite{vanGroenigenEtAl1999}. Sub-sampling leads to the construction of predictive models with little utility, giving a poor representation of the conceptual model of pedogenesis and low prediction accuracy, and over-sampling, which allows building predictive models with great accuracy \cite{vanGroenigenEtAl1999}. But in both cases there is waste of financial resources, staff and time, what is highly undesirable because field sampling is the largest contributor to soil mapping costs \cite{vanGroenigenEtAl1999,KempenEtAl2012,SamuelRosa2012}.

Several (geo)statistical criteria can be used to help defining appropriate calibration sample sizes and designs. For variographic analysis, it is recommended to use more than 100-250 (equidistant) observations, depending on the pattern of spatial distribution of the soil property under analysis \cite{WebsterEtAl2007}. Prior information on the spatial distribution of soil properties can be used coupled with optimization methods that minimize the kriging variance \cite{vanGroenigenEtAl1999,BrusEtAl2007a}. But it is also necessary to obtain a representative sample of the entire range of variation of the environmental co-variates (attribute space) \cite{HenglEtAl2003a} to properly represent the conceptual model of pedogenesis. The variance of the estimated regression coefficients has also to be minimized \cite{BrusEtAl2007a}. Finally, field work effort cannot overcome the available budget and the expected gains of using soil maps \cite{KempenEtAl2012}. Due to these conflicting needs, model building in DSM is a multiple-objective optimization problem for which there is no unique solution, but a set of possible solutions (\textit{Pareto optimality}).

\subsubsection{Environmental co-variates}

Several environmental co-variates can be used to build DSM models, such as terrain attributes, geologic and land use maps, vegetation measures, surface reflectance, legacy soil data, among others \cite{McBratneyEtAl2003}. All of them contain errors. These errors derive from the methods of data generation, analytical procedures and inherent characteristics of each site. For example, digital elevation models (DEM) usually present larger errors in areas with steep slopes, rough terrains and great elevations, and with dense forest cover or urbanized \cite{Florinsky1998,Toutin2000,FisherEtAl2006}. Interpolation of elevation data using kriging can produce spurious artifacts \cite{HenglEtAl2009}. And stereoscopic correlation techniques produce DEMs with poorer quality than interferometric synthetic aperture radar \cite{HirtEtAl2010}.

Finding the ``optimal'' set of environmental co-variates among several uncertain environmental co-variates can be accomplished using automated co-variate selection methods. The main issue is to select the most appropriate method. Some methods analyze all possible combinations of environmental co-variates. Others simulate the process of natural selection (genetic algorithms) \cite{AndersenEtAl2010}. Cross-validation selects environmental co-variates that produce the best predictions on test sets \cite{GuyonEtAl2003}. Other methods take into account the order in which the environmental co-variates are added to (forward selection) or removed from (backward elimination) the model \cite{LarkEtAl2007a}. And the stepwise method adds and removes environmental co-variates until no further addition or removal results in significant change in the model \cite{Efroymson1962}. But the number of problems associated with using these methods can be greater than the number of advantages \cite{Chatfield1995,LarkEtAl2007a}. In the multiple regression case the coefficients of determination and regression coefficients are overestimated, standard errors and \textit{P}-values are sub-estimated, and the multicollinearity problem is not solved \cite{Harrell2001}. Besides, each method selects a different set of environmental co-variates, what constitutes a source of uncertainty regarding model specification \cite{Harrell2001}.

Model building for DSM also depends on dealing with multicollinearity, a deviation from orthogonality that indicates that a environmental co-variate can be explained by other environmental co-variate(s) \cite{FarrarEtAl1967}. Strongly multicollinear environmental co-variates affect estimated parameters of linear models and their confidence intervals \cite{FarrarEtAl1967}, and impair the performance of automated co-variate selection methods \cite{Harrell2001}. One alternative is linearly transforming environmental co-variates to principal components (PCs) \cite{Massy1965}. After orthogonalization we need to select the ``optimum'' set of PCs to build DSM models. Some studies recommend using only the first PCs \cite{Peres-NetoEtAl2005,tenCatenEtAl2011a}, while others show that such criterion has no physical or statistical support \cite{FarrarEtAl1967,Jolliffe2002}. Overall, using all PCs is the same as using all original environmental co-variates and thus not dealing with multicollinearity \cite{FarrarEtAl1967}. Selecting the first PCs solves multicollinearity, but the resulting model is biased, predictive capacity is lost, and interpretation of regression coefficients is too subjective \cite{Massy1965,Jolliffe2002}. Using low variance PCs increases predictive capacity, but explodes the variance of regression coefficients \cite{Jolliffe2002}. Besides, PCs are sensitive to environmental co-variates, their probability distribution and correlation structure, data transformations, measurement scale and outlying observations \cite{Hauser1974,Jolliffe2002,Peres-NetoEtAl2005}. Last, but not least, PCs are simple artificial linear combinations of the original environmental co-variates and have no physical or biological meaning \cite{FarrarEtAl1967}.

\subsubsection{Model structure}

The relation between soil properties and environmental co-variates in a given geomorphic surface seldom is completely linear. In fact, this relation usually is very complex and presents a large variation among different geomorphic surfaces \cite{McKenzieEtAl2000}. Such complexity occurs because many geomorphic surfaces are less stable or have recently undergone strong natural alterations \cite{Schumm1979}. As landscape complexity and rejuvenation increase the environmental co-variates available can loose their ability to explain the spatial distribution of soil properties. Moreover, in areas occupied with intense anthropic activities a series of environmental disturbs can have been caused, being sufficient to make the relation between soil properties and the landscape poorly noticeable. One alternative to map soil properties in these circumstances is to use more complex non-linear trend models, such as artificial neural networks and random forests. In general, these complex trend models have a greater ability to capture more complex site-specific soil-landscape relations \cite{Grunwald2009}. However, data quality (soil observations and environmental co-variates) has been shown to be more important in building a successful model than using more sophisticated statistical methods \cite{ParkEtAl2002,MinasnyEtAl2007}. Besides, non-linear trend models such as artificial neural networks are more difficult to implement and interpret, and can be devoid of any pedological information \cite{Grunwald2009}.

\section{Content of the thesis}

\subsection{Objectives and research questions}

Translating verbal representations of conceptual models that describe reality into mathematical representations of these models is a key step in DSM. There are several sources of uncertainty that may affect the development of such mathematical representations. These sources of uncertainty can be classified into three categories for didactic purposes: a) calibration observations, b) environmental co-variates and c) model structure. The general objective of this project is to evaluate these three main sources of uncertainty in DSM under different database scenarios. This general objective can be divided into five specific objectives with their respective research questions:
\begin{enumerate}
\item Identify appropriate calibration sample sizes and designs;

\subitem [{Research\ Question}] How calibration sample size and sampling design affect model composition, prediction accuracy and monetary cost?

\item Determine the accuracy of freely available environmental co-variates and their suitability for DSM;

\subitem [{Research\ Question}] How accurate are the freely available environmental co-variates and how much uncertainty reduction is achieved when more accurate environmental co-variates are used?

\item Identify appropriate co-variate selection methods to build linear DSM models;

\subitem [{Research\ Question}] How co-variate selection methods affect model composition and prediction accuracy?

\item Assess the effect of multicollinearity on the performance of linear models;

\subitem [{Research\ Question}] How strongly correlated are environmental co-variates and is prediction accuracy improved when they are transformed to their principal components?

\item Identify scenarios in which nonlinear models are more efficient than linear models;

\subitem [{Research\ Question}] In which database scenarios nonlinear models have better performance than linear models?
\end{enumerate}

\subsection{Study area and database}

\subsubsection{Study area}

The soil database used comes from a study area in the southern edge of the plateau of the Paraná Sedimentary Basin, in the state of Rio Grande do Sul, Brazil. This study area is a small catchment (1,892 ha) which constitutes 60\% of the entire catchment of one of the water reservoirs of the city of Santa Maria. Climate is classified as Cfa (Köppen climate classification - subtropical humid without a dry season) with mean annual temperature of $19.3^{\circ}$C, and mean annual precipitation of 1,708 mm well distributed throughout the year \cite{Maluf2000}. Relief varies between plain (slope between 0 and 3\%) and mountainous (slope between 45 and 100\%), and elevations range between 139 and 475 m. There are three main geological formations which consist of (a) basic, intermediate and acid igneous rocks (rhyolite-rhyodacite and andesite-basalt) of the Cretaceous period; (b) consolidated sedimentary rocks (aeolian and fluvial sandstones) of the Triassic and Jurassic periods; and (c) non-consolidated (fluvial and colluvial deposits) of the Quaternary period \cite{GasparettoEtAl1988,MacielFilho1990,Sartori2009}. Forest areas occupy more than half of the study area, followed by native grassland, shrubland, farmland, forestry, urban areas and artificial water bodies \cite{SamuelRosaEtAl2011a}.

\subsubsection{Soil database}

There are $n=350$ calibration observations in the soil database. They were sampled during a soil and land use survey started in 2008 and published in the scale of 1:30,000 \cite{SamuelRosaEtAl2011a,MiguelEtAl2012}. Sampling locations were selected using expert knowledge (purposive
sampling). Soil scientists made soil observations in most common geomorphological features and land uses, and in patches with similar soil taxa, trying to obtain a somehow uniform coverage of the geographic and attribute spaces. Resulting sampling density is of about 0.18 observations per hectare. Average separation distance between two neighboring points is 181 m. Minimum and maximum separation distances are, respectively, 18 and 328 m. Standard deviation is 80 m, and 95\% of neighboring point-pairs are separated by more than 49 m.

During soil sampling, the soil scientists defined an area of about 100 m\texttwosuperior{} around each sampling point. Three soil pits were opened within this area. Soil was collected to a depth of 20 cm, or down to the bedrock when soil depth was smaller than 20 cm. Composite samples were obtained for laboratory analysis. Sample locations were georeferenced using a GNSS navigation receiver with horizontal accuracy of $\pm8$ m. In some situations the GNSS signal was compromised, such as inside forest canopy and deep valleys, resulting in a positional error larger than $\pm8$ m. In such cases georeferencing was performed on the computer screen using Google Earth\textregistered{} satellite images (spatial resolution $<1$ m). Positional error of these images was assumed to be $\pm6$ m from visual assessment.

Sixty ($n=60$) validation samples were collected at regular spacing of 100 m from $n=12$ linear transects of 400 m during the years 2012 and 2013. Sampled transects were randomly selected from a set of $n=180$ transects drawn by three experts in Google Earth\textregistered{}. They were located in areas where experts were almost certain that soil samples could be collected, and aligned in the direction of maximum expected spatial variance of environmental features. Sampling sites were located in the field using a GNSS navigation receiver with horizontal accuracy of $\pm8$ m. A differential GNSS signal receiver with centimetric horizontal precision was used for georeferencing and collection of altimetric data. A single soil sample was collected to a depth of 20 cm (or down to the bedrock when soil depth was smaller than 20 cm) in a soil pit opened within a radius of 2 m.

%\begin{center}
%\begin{figure}[h]
%\centering
%\includegraphics[width=8cm]{/home/alessandro/rdata/dnos_sm/figures/location.pdf}
%\includegraphics[width=8cm]{/home/alessandro/rdata/dnos_sm/figures/sample_points.pdf}
%\caption{Study area location and calibration/validation observations.}
%\label{fig:location-and-points}
%\end{figure}
%\end{center}

Another $n=60$ validation observations will be collected using probability sampling. The area will be subdivided in square cells of 176,400 m\texttwosuperior{} ($420\times420\,\text{m}$). These square cells will be classified in in three strata according to environmental features (geology, relief and vegetation). In each stratum, four ($n=4$) square cells will be randomly selected. Within each cell, $n=5$ sampling points will be randomly selected. Location of sampling points in the field and collection of soil samples will follow the same procedure described above.

\subsubsection{Laboratory Analysis}

Soil samples were air dried, crushed and passed through a 2 mm-sieve prior to laboratory analysis. One laboratory replicate was used to calculate analytical errors. The analysis of the $n=60$ validation samples to be collected in August and September will follow the procedure that follows.

Particle size analysis was performed using NaOH 1 mol $\text{L}{}^{-1}$ as the dispersing agent. The clay fraction (< 0.002 mm) was determined by the pipette method; the sand fraction (0.053 to 2 mm) was determined by wet sieving; and the silt fraction (0.002 to 0.053 mm) was calculated by difference. Soil samples with organic matter content larger than 5\% were submitted to oxidative treatment with $\text{H}_{2}\text{O}_{2}$ prior to the analysis.

Organic carbon content was determined through wet digestion using 0.067 mol $\text{L}^{-1}$ sulfocromic solution {[}$\text{K}_{2}\text{Cr}_{2}\text{O}_{7}+\text{H}_{2}\text{SO}_{4}${]} in a digestion block at 150ºC during 30 min. The solution was titrated using 0.1 mol $\text{L}^{-1}$ ammonium ferrous sulfate {[}$\text{Fe(NH}_{4}\text{)}_{2}\text{(SO}_{4}\text{)}_{2}\text{.6H}_{2}\text{O}${]} and results were multiplied by 1.11 to correct to the standard method (dry combustion).

Effective cation exchange capacity (ECEC) was calculated as the sum of exchangeable bases plus exchangeable acidity. Calcium (Ca) and magnesium (Mg) were quantified by means of atomic absorption spectroscopy, and aluminum (Al) was quantified by titration with 0.025 mol $\text{L}^{-1}$ NaOH solution after extraction with 1.0 mol $\text{L}^{-1}$ KCl solution. Potassium (K) and sodium (Na) were quantified by means of flame atomic emission spectrometry after extraction with 0.05 mol $\text{L}^{-1}$ HCl solution + 0.025 mol $\text{L}^{-1}$ $\text{H}_{2}\text{SO}_{4}$ solution (Mehlich-I solution). Because the standard method for determining exchangeable bases relies on the use of barium chloride ($\text{BaCl}_{2}$), a correction factor will be calculated using $n=60$ soil samples from the soil database. Soil samples will be selected through probability sampling using information on clay content, organic carbon content and sum of bases. Validation will be performed using $n=20$ independent soil samples.

\subsubsection{Environmental co-variates}

There are 20 data layers freely available for the study area. They include information on relief, vegetation, land use, geology, soil parent material, soil (taxa) and intimately-associated surface conditions.

Relief data comes from three DEMs. The first DEM was produced using contour lines of the most recent topographic map produced by the Brazilian Army (scale of 1:20,000). Interpolation was carried out using thin plate spline with drainage enforcement \citep{SamuelRosaEtAl2013a}. The second DEM was produced by NASA through the SRTM project (3 arc-seconds $\thickapprox$ 90 m spatial resolution) and further improved using a hydrologically correct interpolation method (\textit{hole-filled SRTM version 4}) \citep{ReuterEtAl2007,Jarvis2008}. The third DEM was produced by the Brazilian National Institute for Space Research (INPE) through refining the original SRTM DEM to 1 arc-second spatial resolution ($\thickapprox$30 m) using ordinary kriging \citep{ValerianoEtAl2012}.

Vegetation and land use data comes from land use maps and orbital images. A land use map for the year of 1980 comes from the most recent topographic map produced by the Brazilian Army (scale of 1:20,000). A second land use map is available for the years of 2008 and 2009 and was published at a scale of 1:30,000 \citep{SamuelRosaEtAl2011a}. There are ten orbital images acquired by Landsat-5 Thematic Mapper between 1986 and 2010. All orbital images contain 7 spectral bands, with 8 bits radiometric resolution and 30 meters spatial resolution. Atmospheric interferences were removed using the 6S atmospheric model \citep{VermoteEtAl1997} and orthorrectification was done using the 30 meter resolution DEM produced by INPE. Another orbital image was acquired in 2011 by the RapidEye satellite constellation and made available by the Brazilian Ministry of the Environment \citep{Brasil2012}. This orbital image contains 5 spectral bands, with 12 bits radiometric resolution and 6.5 meters spatial resolution, and was orthorrectified to 5 meters spatial resolution \citep{RapidEye2013}.

Data on geology and soil parent material data comes from most recent geological maps published in the scales of 1:25,000 \citep{MacielFilho1990} and 1:50,000 \citep{GasparettoEtAl1988}. Data on soil (taxa) and intimately-associated surface conditions comes from the latest pedological maps published in the scales of 1:30,000 \citep{MiguelEtAl2012} and 1:100,000 \citep{AzolinEtAl1988}.

\subsection{Outline}

Chapter 1 will deal with assessing the accuracy of freely available environmental co-variates and whether investing in more accurate environmental co-variates improves prediction accuracy.

Chapter 2 will deal with identifying appropriate calibration sample sizes and sampling designs for building linear DSM models for mapping soil properties.

Chapter 3 will deal with evaluating automated methods used to select environmental co-variates to build linear DSM models on how they affect model composition and prediction accuracy.

Chapter 4 will deal with evaluating multicollinearity effects on the performance of linear DSM models and whether transforming environmental co-variates to principal components (PCs) is a better way of dealing with it.

Chapter 5 will deal with identifying database scenarios regarding the number of calibration observations available in which non-linear models present better performance than linear models.